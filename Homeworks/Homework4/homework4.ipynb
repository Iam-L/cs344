{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# CS-344: Homework 04 - Classification\n",
    "\n",
    "by Joseph Jinn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For kicks and giggles:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"ml_meme.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO - Revise essay for Part 1.\n",
    "# TODO - Double check calculations for Part 2.\n",
    "# TODO - Play around with the network to increase accuracy, precision, and other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Part 1: Deep Neural Networks - Bust or Breakthrough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Given that machine learning is one of my areas of interest for graduate studies, I sure as hell hope they aren’t going to be a bust anytime in the foreseeable future.  In my humble opinion, I believe deep neural networks still possesses significant potential for growth and research.</p>\n",
    "\n",
    "What I really want to see are MMORPG’s (massively multiplayer online role-playing games), such as the classic example of World of Warcraft, that implement some form of advanced Artificial Intelligence.  Given the current state of that genre, AI is pretty limited in those games to scripted behavior that rely on very simple decision trees in the background.  It’s one of the reasons I don’t find MMO’s as fun as sandbox open world RPG’s like the Elder Scrolls 5: Skyrim, despite the sometimes god-awful “Radiant AI” system that governs the NPC’s.  You would think a Non-Player character should at least be able to path-find around a boulder the size of a shack.  Then again, Bethesda’s not known for its software engineering skills.</p>\n",
    "\n",
    "I would love to feed a neural network all the 3d models of rock in Skyrim as a training set and see if I can get the network to accurately predict what constitutes a “rock” or “not a rock”.  Then, apply the resulting model to the NPC’s and see if they can now path-find their way around rocky outcroppings and not run in-place against a pebble on the ground.</p>\n",
    "\n",
    "Searching around Google a bit, I came upon an interesting article entitled “Neural MMO: A Massively Multiagent Game Environment”.  Lo and behold, some researchers actually are implementing deep neural networks in the context of MMO’s.  What’s even better, the article is dated on March 4, 2019, so it is recent.  And far more wonderful is that the source code for their research is available on Github.  I wouldn’t mind experimenting with this sometime in the near future.</p>\n",
    "\n",
    "Neural MMO is a “massively multi-agent game environment for reinforcement learning agents”.  The description of this model states that players (the agents) can join any available server (environment) that contains a procedurally generated tile-based game map of configurable size.  The input is described “agents observe a square crop of tiles centered on their current position – including tile terrain types and select properties (health, food, water, and position) of occupying agents.  The output is described as “agents output action choices for the next game tick (time-step) – actions consist of one movement and one attack”.</p>\n",
    "\n",
    "Now, if only theoretical research like this can lead to practical application in developing a living, breathing world in sandbox RPG’s and MMORPG's that simulate the living ecosystem we have on Earth.  Then, I could become a NEET (“Not in Education, Employment, or Training”) and enjoy myself in a virtual environment 24/7.  Just kidding.  But hey, this still gives reason to believe that deep neural networks still have the potential for growth and research leading to more and more practical applications in our daily lives.  So hopefully, this area of AI doesn’t die off till long after I’ve obtained a Ph.D. in computer science, published a few papers, and grown old and bald, barring unforeseen fatal circumstances.</p>\n",
    "\n",
    "URL: https://openai.com/blog/neural-mmo/<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Part 2: Back-Propagation Cycle - Hand Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Page 1:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(90deg); margin: 0 10px 10px 0\" src=\"hw04-part2-page1.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Page 2:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(90deg); margin: 0 10px 10px 0\" src=\"hw04-part2-page2.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page 3:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(90deg); margin: 0 10px 10px 0\" src=\"hw04-part2-page3.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Part 3: Keras Fashion MNIST Dataset - Keras-based Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information concerning the Fashion MNIST Dataset:\n",
    "    \n",
    "Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:\n",
    "\n",
    "60,000 training examples<br>\n",
    "10,000 testing examples<br>\n",
    "10 classes<br>\n",
    "28×28 grayscale/single channel images<br>\n",
    "The ten fashion class labels include:<br>\n",
    "\n",
    "T-shirt/top<br>\n",
    "Trouser/pants<br>\n",
    "Pullover shirt<br>\n",
    "Dress<br>\n",
    "Coat<br>\n",
    "Sandal<br>\n",
    "Shirt<br>\n",
    "Sneaker<br>\n",
    "Bag<br>\n",
    "Ankle boot<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "Training data shape:\n",
      "(60000, 28, 28)\n",
      "Training targets shape:\n",
      "(60000,)\n",
      "Testing data shape:\n",
      "(10000, 28, 28)\n",
      "Testing targets shape:\n",
      "(10000,)\n",
      "\n",
      "Training images[0]:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after reshape:\n",
      "(60000, 28, 28, 1)\n",
      "Testing data shape after reshape:\n",
      "(10000, 28, 28, 1)\n",
      "\n",
      "Training targets shape after one-hot encoding:\n",
      "(60000, 10)\n",
      "Testing targets shape after one-hot encoding:\n",
      "(10000, 10)\n",
      "\n",
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From d:\\dropbox\\cs344-ai\\venv3.6-64bit\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From d:\\dropbox\\cs344-ai\\venv3.6-64bit\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From d:\\dropbox\\cs344-ai\\venv3.6-64bit\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.5853 - acc: 0.7944 - val_loss: 0.4463 - val_acc: 0.8386\n",
      "10000/10000 [==============================] - 0s 26us/step\n",
      "Test dataset accuracy: 0.8386\n",
      "Test dataset loss: 0.44627747938632967\n",
      "Prediction sample:\n",
      "[5.2071186e-06 2.7307613e-05 8.9345567e-06 1.2221341e-05 1.1038514e-05\n",
      " 1.0330002e-01 2.6393427e-06 2.1083897e-01 4.6952936e-04 6.8532413e-01]\n",
      "Highest class confidence value:\n",
      "9\n",
      "Associated test label value:\n",
      "9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4000x4000 with 400 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: \n",
      "(28, 28, 1)\n",
      "\n",
      "Image batch shape: \n",
      "(1, 28, 28, 1)\n",
      "\n",
      "Image batch prediction results: \n",
      "[[5.20711183e-06 2.73075493e-05 8.93454398e-06 1.22213251e-05\n",
      "  1.10384890e-05 1.03299886e-01 2.63934430e-06 2.10838690e-01\n",
      "  4.69529012e-04 6.85324550e-01]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.79      0.82      0.80      1000\n",
      "     Trouser       0.99      0.95      0.97      1000\n",
      "    Pullover       0.72      0.74      0.73      1000\n",
      "       Dress       0.83      0.86      0.84      1000\n",
      "        Coat       0.74      0.73      0.74      1000\n",
      "      Sandal       0.95      0.91      0.93      1000\n",
      "       Shirt       0.60      0.56      0.58      1000\n",
      "     Sneaker       0.90      0.93      0.91      1000\n",
      "         Bag       0.93      0.95      0.94      1000\n",
      "  Ankle boot       0.92      0.94      0.93      1000\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Course: CS 344 - Artificial Intelligence\n",
    "Instructor: Professor VanderLinden\n",
    "Name: Joseph Jinn\n",
    "Date: 4-1-19\n",
    "\n",
    "Homework 4 - Classification\n",
    "Keras Fashion MNIST Dataset - Keras-based Convolutional Neural Network\n",
    "\n",
    "Notes:\n",
    "\n",
    "I took material from two tutorials and sort of meshed them together.\n",
    "\n",
    "I don't pretend to understand everything that's happening, but it seems to be a working CNN.\n",
    "\n",
    "############################################\n",
    "\n",
    "Resources Used:\n",
    "\n",
    "URL: https://www.tensorflow.org/tutorials/keras/basic_classification\n",
    "(Keras Tensorflow tutorial)\n",
    "\n",
    "URL: https://developers.google.com/machine-learning/practica/image-classification/\n",
    "(Google Crash Course)\n",
    "\n",
    "URL: https://www.markdownguide.org/basic-syntax/\n",
    "(Markdown syntac for Juypter Notebook)\n",
    "\n",
    "URL: https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/\n",
    "(Keras Fashion MNIST Tutorial)\n",
    "\n",
    "URL: https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
    "(Keras Convolutional Layers)\n",
    "\n",
    "############################################\n",
    "\n",
    "Assignment Instructions:\n",
    "\n",
    "Build a Keras-based ConvNet for Keras’s Fashion MNIST dataset (fashion_mnist). Experiment with different network\n",
    "architectures, submit your most performant network, and report the results.\n",
    "\n",
    "\"\"\"\n",
    "############################################################################################\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from imutils import build_montages\n",
    "import cv2\n",
    "\n",
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 1\n",
    "INIT_LR = 1e-2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "# import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Label\tClass\n",
    "0\tT-shirt/top\n",
    "1\tTrouser\n",
    "2\tPullover\n",
    "3\tDress\n",
    "4\tCoat\n",
    "5\tSandal\n",
    "6\tShirt\n",
    "7\tSneaker\n",
    "8\tBag\n",
    "9\tAnkle boot\n",
    "\"\"\"\n",
    "\n",
    "# Load the dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Column headers.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(\"Training data shape:\")\n",
    "print(train_images.shape)\n",
    "print(\"Training targets shape:\")\n",
    "print(train_labels.shape)\n",
    "print(\"Testing data shape:\")\n",
    "print(test_images.shape)\n",
    "print(\"Testing targets shape:\")\n",
    "print(test_labels.shape)\n",
    "print()\n",
    "\n",
    "# Display 1st image in training set.\n",
    "print(\"Training images[0]:\")\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Pre-process dataset.\n",
    "\"\"\"\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "train_images = train_images.astype(\"float32\") / 255.0\n",
    "test_images = test_images.astype(\"float32\") / 255.0\n",
    "\n",
    "# Display first 25 images in training set.\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n",
    "\n",
    "# If we are using \"channels first\" ordering, then reshape the design\n",
    "# matrix such that the matrix is:\n",
    "# \tnum_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    train_images_reshaped = train_images.reshape((train_images.shape[0], 1, 28, 28))\n",
    "    test_images_reshaped = test_images.reshape((test_images.shape[0], 1, 28, 28))\n",
    "\n",
    "# Otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "    train_images_reshaped = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "    test_images_reshaped = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "print(\"Training data shape after reshape:\")\n",
    "print(train_images_reshaped.shape)\n",
    "print(\"Testing data shape after reshape:\")\n",
    "print(test_images_reshaped.shape)\n",
    "print()\n",
    "\n",
    "# One-hot encode the training and testing labels.\n",
    "train_labels_one_hot = np_utils.to_categorical(train_labels, 10)\n",
    "test_labels_one_hot = np_utils.to_categorical(test_labels, 10)\n",
    "\n",
    "print(\"Training targets shape after one-hot encoding:\")\n",
    "print(train_labels_one_hot.shape)\n",
    "print(\"Testing targets shape after one-hot encoding:\")\n",
    "print(test_labels_one_hot.shape)\n",
    "print()\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "tf.keras.layers.Flatten - Flattens the input. Does not affect the batch size. (2-d to 1-d array)\n",
    "\n",
    "tf.keras.layers.Dense - densely-connected, or fully-connected, neural layers.\n",
    "\n",
    "10-node softmax layer—this returns an array of 10 probability scores that sum to 1\n",
    "\n",
    "Pooling layers help to progressively reduce the spatial dimensions of the input volume.\n",
    "\n",
    "Batch normalization seeks to normalize the activations of a given input volume before passing it into the next layer. \n",
    "It has been shown to be effective at reducing the number of epochs required to train a CNN at the expense of an \n",
    "increase in per-epoch time.\n",
    "\n",
    "Dropout is a form of regularization that aims to prevent overfitting. \n",
    "Random connections are dropped to ensure that no single node in the network is responsible for activating \n",
    "when presented with a given pattern.\n",
    "\n",
    "What follows is a fully-connected layer and softmax classifier (Lines 49-57). \n",
    "The softmax classifier is used to obtain output classification probabilities.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build(width, height, depth, classes):\n",
    "    # initialize the model along with the input shape to be\n",
    "    # \"channels last\" and the channels dimension itself\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    # if we are using \"channels first\", update the input shape\n",
    "    # and channels dimension\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "\n",
    "    # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "                     input_shape=inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # second CONV => RELU => CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # softmax classifier\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    # return the constructed network architecture\n",
    "    return model\n",
    "\n",
    "\n",
    "# # Setup the layers.\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "# ])\n",
    "\n",
    "\"\"\"\n",
    "Loss function —This measures how accurate the model is during training. \n",
    "We want to minimize this function to \"steer\" the model in the right direction.\n",
    "\n",
    "Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
    "\n",
    "Metrics —Used to monitor the training and testing steps. The following example uses accuracy, \n",
    "the fraction of the images that are correctly classified\n",
    "\"\"\"\n",
    "\n",
    "# # Compile the model.\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "\"\"\"\n",
    "Feed the training data to the model—in this example, the train_images and train_labels arrays.\n",
    "\n",
    "The model learns to associate images and labels.\n",
    "\n",
    "We ask the model to make predictions about a test set—in this example, the test_images array. \n",
    "We verify that the predictions match the labels from the test_labels array.\n",
    "\"\"\"\n",
    "\n",
    "# Train the model.\n",
    "train_model = model.fit(train_images_reshaped, train_labels_one_hot,\n",
    "                        validation_data=(test_images_reshaped, test_labels_one_hot),\n",
    "                        batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Evaluate accuracy.\n",
    "\"\"\"\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images_reshaped, test_labels_one_hot)\n",
    "\n",
    "print('Test dataset accuracy:', test_acc)\n",
    "print('Test dataset loss:', test_loss)\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Make predictions.\n",
    "\"\"\"\n",
    "predictions = model.predict(test_images_reshaped)\n",
    "\n",
    "# Prediction sample\n",
    "print(\"Prediction sample:\")\n",
    "print(predictions[0])\n",
    "\n",
    "# Get highest confidence value from prediction array.\n",
    "print(\"Highest class confidence value:\")\n",
    "print(np.argmax(predictions[0]))\n",
    "\n",
    "# Confirm against associated test label.\n",
    "print(\"Associated test label value:\")\n",
    "print(test_labels[0])\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    \"\"\"\n",
    "    Function outputs a graph of the image.\n",
    "\n",
    "    :param i:\n",
    "    :param predictions_array:\n",
    "    :param true_label:\n",
    "    :param img:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100 * np.max(predictions_array),\n",
    "                                         class_names[true_label]),\n",
    "               color=color)\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    \"\"\"\n",
    "    Function outputs the prediction array with set of confidence values associated with classes.\n",
    "\n",
    "    :param i:\n",
    "    :param predictions_array:\n",
    "    :param true_label:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def visualize_results(predictions):\n",
    "    \"\"\"\n",
    "    Function visualizes the results of training the model.\n",
    "\n",
    "    :return: Nothing.\n",
    "    \"\"\"\n",
    "    # show a nicely formatted classification report\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    print(classification_report(test_labels_one_hot.argmax(axis=1), predictions.argmax(axis=1),\n",
    "                                target_names=class_names))\n",
    "\n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"training_loss_accuracy_plot.png\")\n",
    "\n",
    "    # # initialize our list of output images\n",
    "    # images = []\n",
    "    #\n",
    "    # # randomly select a few testing fashion items\n",
    "    # for i in np.random.choice(np.arange(0, len(test_labels_one_hot)), size=(16,)):\n",
    "    #     # classify the clothing\n",
    "    #     probs = model.predict(test_images_reshaped[np.newaxis, i])\n",
    "    #     prediction = probs.argmax(axis=1)\n",
    "    #     label = class_names[prediction[0]]\n",
    "    #\n",
    "    #     # extract the image from the testData if using \"channels_first\"\n",
    "    #     # ordering\n",
    "    #     if K.image_data_format() == \"channels_first\":\n",
    "    #         image = (test_images_reshaped[i][0] * 255).astype(\"uint8\")\n",
    "    #\n",
    "    #     # otherwise we are using \"channels_last\" ordering\n",
    "    #     else:\n",
    "    #         image = (test_labels_one_hot[i] * 255).astype(\"uint8\")\n",
    "    #\n",
    "    #     # initialize the text label color as green (correct)\n",
    "    #     color = (0, 255, 0)\n",
    "    #\n",
    "    #     # otherwise, the class label prediction is incorrect\n",
    "    #     if prediction[0] != np.argmax(test_labels[i]):\n",
    "    #         color = (0, 0, 255)\n",
    "    #\n",
    "    #     # merge the channels into one image and resize the image from\n",
    "    #     # 28x28 to 96x96 so we can better see it and then draw the\n",
    "    #     # predicted label on the image\n",
    "    #     image = cv2.merge([image] * 3)\n",
    "    #     image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    #     cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "    #                 color, 2)\n",
    "    #\n",
    "    #     # add the image to our list of output images\n",
    "    #     images.append(image)\n",
    "    #\n",
    "    # # construct the montage for the images\n",
    "    # montage = build_montages(images, (96, 96), (4, 4))[0]\n",
    "    #\n",
    "    # # show the output montage\n",
    "    # cv2.imshow(\"Fashion MNIST\", montage)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "\"\"\"\n",
    "Main function.  Execute the program.\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    print()\n",
    "\n",
    "    # Visualize 0th image, predictions, and prediction array.\n",
    "    i = 0\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_image(i, predictions, test_labels, test_images)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_value_array(i, predictions, test_labels)\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize the 12th image, predictions, and prediction array.\n",
    "    i = 12\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_image(i, predictions, test_labels, test_images)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_value_array(i, predictions, test_labels)\n",
    "    plt.show()\n",
    "\n",
    "    # import random\n",
    "    #\n",
    "    # my_range = random.randint(1, 50000)\n",
    "\n",
    "    # Plot the first X test images, their predicted label, and the true label\n",
    "    # Color correct predictions in blue, incorrect predictions in red\n",
    "    num_rows = 20\n",
    "    num_cols = 10\n",
    "    num_images = num_rows * num_cols\n",
    "    plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
    "        plot_image(i, predictions, test_labels, test_images)\n",
    "        plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n",
    "        plot_value_array(i, predictions, test_labels)\n",
    "    plt.show()\n",
    "\n",
    "    ##############################################\n",
    "\n",
    "    # Grab an image from the test dataset.\n",
    "    img = test_images_reshaped[0]\n",
    "\n",
    "    print(\"Image shape: \")\n",
    "    print(img.shape)\n",
    "    print()\n",
    "\n",
    "    # Add the image to a batch where it's the only member.\n",
    "    img = (np.expand_dims(img, 0))\n",
    "\n",
    "    print(\"Image batch shape: \")\n",
    "    print(img.shape)\n",
    "    print()\n",
    "\n",
    "    # Predict the images in the batch.\n",
    "    predictions_single = model.predict(img)\n",
    "\n",
    "    print(\"Image batch prediction results: \")\n",
    "    print(predictions_single)\n",
    "    print()\n",
    "\n",
    "    ##############################################\n",
    "\n",
    "    # Visualize the results of the batch image predictions.\n",
    "    plot_value_array(0, predictions_single, test_labels)\n",
    "    _ = plt.xticks(range(10), class_names, rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Get the max confidence value result signifying which class it belongs to in the labels.\n",
    "    np.argmax(predictions_single[0])\n",
    "\n",
    "    # Visualize results.\n",
    "    visualize_results(predictions)\n",
    "\n",
    "############################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fashion MNIST Sample Training Image:\n",
    "\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_training_image[0].png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fashion MNIST Image Preprocessing:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_training_images_preprocess.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fashion MNIST Image Prediction Array (probabilities for each class for a single example)\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_image_prediction_array.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Fashion MNIST Image Prediction Results (array of examples)\n",
    "\n",
    "Note: Blue = correct prediction, Red = incorrect prediction<br>\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_test_images_prediction_results.png\" />\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_test_images_prediction_results2.png\" />\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_test_images_prediction_results3.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
