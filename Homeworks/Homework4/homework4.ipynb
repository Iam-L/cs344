{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# CS-344: Homework 04 - Classification\n",
    "\n",
    "by Joseph Jinn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### For kicks and giggles:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"ml_meme.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Part 1: Deep Neural Networks - Bust or Breakthrough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "I speculate that deep neural networks will last at least within my limited lifespan.  Google, who we all know and love, use deep neural networks in standard features of their search engine, such as Google Images.  If giant mega tech corporations are applying machine learning in their commercial products, I doubt it is going away anytime soon.  Insofar as it remains profitable.</p>\n",
    "\n",
    "There is a steady stream of on-going research involving machine learning.  As one example, my summer 2019 research with Professor VanderLinden.  As another example, AlphaStar, the Starcraft 2 AI that is capable of defeating professional players.  Perusing the deepmind.com blog I saw articles describing research on breast cancer screening via machine learning conducted by Google DeepMind Health.  Apparently, Google acquired DeepMind a while back, which I was not aware of.  Another post described how machine learning was applied to Google’s wind farms to predict optimal hourly delivery commitments to a power grid a full day in advance.  So on and so forth.</p>\n",
    "\n",
    "With continuing improvements in technology, we will have access to more powerful CPU’s, GPU’s, more RAM/VRAM, etc.  This will only increase the viability of machine learning as an established field with theoretical and practical applications.  It will be more computationally feasible to train on models containing very numerous (deep) layers and a large number of nodes.  At Calvin, we have the “Borg” super-computer with 4 Nvidia Titans.  Tensorflow and other machine learning API are highly parallelizable and scalable.  Keras, a more user-friendly API capable of running on top of Tensorflow allows for fast prototyping so even the average layman could become involved with a simple tutorial or two.</p>\n",
    "\n",
    "I believe that machine learning is still in its adolescent phase and has yet to mature.  Anyone with a system with decent specifications could install the necessary software and train a machine learning model to predict something.  This isn’t some prohibitively inaccessible field where you need millions of dollars and a Ph.D. from UC-Berkeley in order to get started.  You don’t necessarily need a degree in Statistics to understand the results either.  Google’s Machine Learning Crash Course will do just fine.  In conclusion, deep neural networks should be a breakthrough that will last throughout the 21st century, if not beyond.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Part 2: Back-Propagation Cycle - Hand Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Note:  The images are cut off at the top and bottom.  I have the .png's for these in the Homework04 directory of my repository.  I will also probably have turned in a hard-copy to you before the due date. =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Page 1:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(90deg); margin: 0 10px 10px 0\" src=\"hw04-part2-page1.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Page 2:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(90deg); margin: 0 10px 10px 0\" src=\"hw04-part2-page2.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Page 3:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(90deg); margin: 0 10px 10px 0\" src=\"hw04-part2-page3.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Part 3: Keras Fashion MNIST Dataset - Keras-based Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Information concerning the Fashion MNIST Dataset:\n",
    "    \n",
    "Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:\n",
    "\n",
    "60,000 training examples<br>\n",
    "10,000 testing examples<br>\n",
    "10 classes<br>\n",
    "28×28 grayscale/single channel images<br>\n",
    "The ten fashion class labels include:<br>\n",
    "\n",
    "T-shirt/top<br>\n",
    "Trouser/pants<br>\n",
    "Pullover shirt<br>\n",
    "Dress<br>\n",
    "Coat<br>\n",
    "Sandal<br>\n",
    "Shirt<br>\n",
    "Sneaker<br>\n",
    "Bag<br>\n",
    "Ankle boot<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "Training data shape:\n",
      "(60000, 28, 28)\n",
      "Training targets shape:\n",
      "(60000,)\n",
      "Testing data shape:\n",
      "(10000, 28, 28)\n",
      "Testing targets shape:\n",
      "(10000,)\n",
      "\n",
      "Training images[0]:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after reshape:\n",
      "(60000, 28, 28, 1)\n",
      "Testing data shape after reshape:\n",
      "(10000, 28, 28, 1)\n",
      "\n",
      "Training targets shape after one-hot encoding:\n",
      "(60000, 10)\n",
      "Testing targets shape after one-hot encoding:\n",
      "(10000, 10)\n",
      "\n",
      "WARNING:tensorflow:From d:\\dropbox\\cs344-ai\\venv3.6-64bit\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From d:\\dropbox\\cs344-ai\\venv3.6-64bit\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From d:\\dropbox\\cs344-ai\\venv3.6-64bit\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.6149 - acc: 0.7874 - val_loss: 0.4729 - val_acc: 0.8263\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.4847 - acc: 0.8274 - val_loss: 0.4303 - val_acc: 0.8474\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.4410 - acc: 0.8433 - val_loss: 0.4079 - val_acc: 0.8522\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.4209 - acc: 0.8494 - val_loss: 0.3965 - val_acc: 0.8561\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.4036 - acc: 0.8542 - val_loss: 0.3797 - val_acc: 0.8612\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.3894 - acc: 0.8595 - val_loss: 0.3697 - val_acc: 0.8673\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3820 - acc: 0.8612 - val_loss: 0.3627 - val_acc: 0.8674\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.3693 - acc: 0.8664 - val_loss: 0.3576 - val_acc: 0.8695\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3640 - acc: 0.8685 - val_loss: 0.3593 - val_acc: 0.8686\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3570 - acc: 0.8710 - val_loss: 0.3506 - val_acc: 0.8745\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.3497 - acc: 0.8736 - val_loss: 0.3483 - val_acc: 0.8752\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.3442 - acc: 0.8750 - val_loss: 0.3448 - val_acc: 0.8761\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.3394 - acc: 0.8763 - val_loss: 0.3454 - val_acc: 0.8769\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.3382 - acc: 0.8780 - val_loss: 0.3403 - val_acc: 0.8789\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.3322 - acc: 0.8789 - val_loss: 0.3392 - val_acc: 0.8759\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3254 - acc: 0.8825 - val_loss: 0.3398 - val_acc: 0.8773\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.3244 - acc: 0.8814 - val_loss: 0.3373 - val_acc: 0.8784\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.3243 - acc: 0.8825 - val_loss: 0.3347 - val_acc: 0.8781\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.3204 - acc: 0.8838 - val_loss: 0.3333 - val_acc: 0.8791\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3162 - acc: 0.8849 - val_loss: 0.3358 - val_acc: 0.8793\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.3121 - acc: 0.8855 - val_loss: 0.3347 - val_acc: 0.8784\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.3112 - acc: 0.8861 - val_loss: 0.3316 - val_acc: 0.8829\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.3091 - acc: 0.8881 - val_loss: 0.3317 - val_acc: 0.8807\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.3078 - acc: 0.8875 - val_loss: 0.3313 - val_acc: 0.8823\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3048 - acc: 0.8898 - val_loss: 0.3275 - val_acc: 0.8822\n",
      "10000/10000 [==============================] - 0s 26us/step\n",
      "\n",
      "Test dataset accuracy: 0.8822\n",
      "Test dataset loss: 0.327498046875\n",
      "\n",
      "\n",
      "\n",
      "Prediction for the randomly chosen image:\n",
      "[5.88418730e-03 2.46823241e-04 5.17997444e-02 8.74542654e-01\n",
      " 4.56983149e-02 1.45562335e-05 2.14860085e-02 3.05128760e-05\n",
      " 2.89908377e-04 7.18738875e-06]\n",
      "\n",
      "Highest class confidence value for the image:\n",
      "3\n",
      "Associated test label value for the image:\n",
      "2\n",
      "\n",
      "Randomly chosen image's shape: \n",
      "(28, 28, 1)\n",
      "\n",
      "Randomly chosen image's shape in batch it was added to: \n",
      "(1, 28, 28, 1)\n",
      "\n",
      "Randomly chosen image's batch prediction results: \n",
      "[[5.8841826e-03 2.4682304e-04 5.1799737e-02 8.7454277e-01 4.5698300e-02\n",
      "  1.4556207e-05 2.1485988e-02 3.0512880e-05 2.8990814e-04 7.1873833e-06]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest class confidence value for the image in the batch:\n",
      "3\n",
      "Associated test label value for the image in the batch:\n",
      "2\n",
      "\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.86      0.81      0.84      1000\n",
      "     Trouser       0.99      0.97      0.98      1000\n",
      "    Pullover       0.79      0.79      0.79      1000\n",
      "       Dress       0.89      0.89      0.89      1000\n",
      "        Coat       0.78      0.82      0.80      1000\n",
      "      Sandal       0.98      0.95      0.96      1000\n",
      "       Shirt       0.69      0.70      0.69      1000\n",
      "     Sneaker       0.93      0.96      0.94      1000\n",
      "         Bag       0.97      0.97      0.97      1000\n",
      "  Ankle boot       0.96      0.95      0.96      1000\n",
      "\n",
      "   micro avg       0.88      0.88      0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Course: CS 344 - Artificial Intelligence\n",
    "Instructor: Professor VanderLinden\n",
    "Name: Joseph Jinn\n",
    "Date: 4-1-19\n",
    "\n",
    "Homework 4 - Classification\n",
    "Keras Fashion MNIST Dataset - Keras-based Convolutional Neural Network\n",
    "\n",
    "Notes:\n",
    "\n",
    "I took material from two tutorials and sort of meshed them together.\n",
    "\n",
    "I don't pretend to understand everything that's happening, but it seems to be a working CNN.\n",
    "\n",
    "############################################\n",
    "\n",
    "Resources Used:\n",
    "\n",
    "URL: https://www.tensorflow.org/tutorials/keras/basic_classification\n",
    "(Keras Tensorflow tutorial)\n",
    "\n",
    "URL: https://developers.google.com/machine-learning/practica/image-classification/\n",
    "(Google Crash Course)\n",
    "\n",
    "URL: https://www.markdownguide.org/basic-syntax/\n",
    "(Markdown syntax for Juypter Notebook)\n",
    "\n",
    "URL: https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/\n",
    "(Keras Fashion MNIST Tutorial)\n",
    "\n",
    "URL: https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
    "(Keras Convolutional Layers)\n",
    "\n",
    "############################################\n",
    "\n",
    "Assignment Instructions:\n",
    "\n",
    "Build a Keras-based ConvNet for Keras’s Fashion MNIST dataset (fashion_mnist). Experiment with different network\n",
    "architectures, submit your most performant network, and report the results.\n",
    "\n",
    "\"\"\"\n",
    "############################################################################################\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the number of epochs to train for, base learning rate, and batch size.\n",
    "NUM_EPOCHS = 25\n",
    "LEARNING_RATE = 1e-2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Label\tClass\n",
    "0\tT-shirt/top\n",
    "1\tTrouser\n",
    "2\tPullover\n",
    "3\tDress\n",
    "4\tCoat\n",
    "5\tSandal\n",
    "6\tShirt\n",
    "7\tSneaker\n",
    "8\tBag\n",
    "9\tAnkle boot\n",
    "\"\"\"\n",
    "# Load the dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Column headers.\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(\"Training data shape:\")\n",
    "print(train_images.shape)\n",
    "print(\"Training targets shape:\")\n",
    "print(train_labels.shape)\n",
    "print(\"Testing data shape:\")\n",
    "print(test_images.shape)\n",
    "print(\"Testing targets shape:\")\n",
    "print(test_labels.shape)\n",
    "print()\n",
    "\n",
    "# Display 1st image in training set.\n",
    "print(\"Training images[0]:\")\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Pre-process dataset.\n",
    "\"\"\"\n",
    "\n",
    "# Scale data to the range of [0, 1].\n",
    "train_images = train_images.astype(\"float32\") / 255.0\n",
    "test_images = test_images.astype(\"float32\") / 255.0\n",
    "\n",
    "# Display first 25 images in training set.\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n",
    "\n",
    "# If we are using \"channels first\" ordering, then reshape the design matrix such that the matrix is:\n",
    "# num_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    train_images_reshaped = train_images.reshape((train_images.shape[0], 1, 28, 28))\n",
    "    test_images_reshaped = test_images.reshape((test_images.shape[0], 1, 28, 28))\n",
    "\n",
    "# Otherwise, we are using \"channels last\" ordering, so the design matrix shape should be:\n",
    "# num_samples x rows x columns x depth\n",
    "else:\n",
    "    train_images_reshaped = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "    test_images_reshaped = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "\n",
    "print(\"Training data shape after reshape:\")\n",
    "print(train_images_reshaped.shape)\n",
    "print(\"Testing data shape after reshape:\")\n",
    "print(test_images_reshaped.shape)\n",
    "print()\n",
    "\n",
    "# One-hot encode the training and testing labels.\n",
    "train_labels_one_hot = np_utils.to_categorical(train_labels, 10)\n",
    "test_labels_one_hot = np_utils.to_categorical(test_labels, 10)\n",
    "\n",
    "print(\"Training targets shape after one-hot encoding:\")\n",
    "print(train_labels_one_hot.shape)\n",
    "print(\"Testing targets shape after one-hot encoding:\")\n",
    "print(test_labels_one_hot.shape)\n",
    "print()\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "tf.keras.layers.Flatten - Flattens the input. Does not affect the batch size. (2-d to 1-d array)\n",
    "\n",
    "tf.keras.layers.Dense - densely-connected, or fully-connected, neural layers.\n",
    "\n",
    "10-node softmax layer—this returns an array of 10 probability scores that sum to 1.\n",
    "\n",
    "Pooling layers help to progressively reduce the spatial dimensions of the input volume.\n",
    "\n",
    "Batch normalization seeks to normalize the activations of a given input volume before passing it into the next layer. \n",
    "It has been shown to be effective at reducing the number of epochs required to train a CNN at the expense of an \n",
    "increase in per-epoch time.\n",
    "\n",
    "Dropout is a form of regularization that aims to prevent overfitting. \n",
    "Random connections are dropped to ensure that no single node in the network is responsible for activating \n",
    "when presented with a given pattern.\n",
    "\n",
    "What follows is a fully-connected layer and softmax classifier (Lines 49-57). \n",
    "The softmax classifier is used to obtain output classification probabilities.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build(width, height, depth, classes):\n",
    "    \"\"\"\n",
    "    Function builds the machine learning. my_model.\n",
    "    \n",
    "    :param width:  width of the image file in pixels.\n",
    "    :param height:  height of the image file in pixels.\n",
    "    :param depth:  the channels - r,g,b,a.\n",
    "    :param classes: all the possible labels for each image.\n",
    "    :return: the constructed machine learning my_model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the my_model along with the input shape to be \"channels last\" and the channels dimension itself.\n",
    "    my_model = Sequential()\n",
    "    input_shape = (height, width, depth)\n",
    "    channel_dimensions = -1\n",
    "\n",
    "    # If we are using \"channels first\", update the input shape and channels dimension.\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        input_shape = (depth, height, width)\n",
    "        channel_dimensions = 1\n",
    "\n",
    "    # First CONV => RELU => CONV => RELU => POOL layer set.\n",
    "    my_model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "                        input_shape=input_shape))\n",
    "    my_model.add(Activation(\"relu\"))\n",
    "    my_model.add(BatchNormalization(axis=channel_dimensions))\n",
    "    my_model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    my_model.add(Activation(\"relu\"))\n",
    "    my_model.add(BatchNormalization(axis=channel_dimensions))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    my_model.add(Dropout(0.25))\n",
    "\n",
    "    # Second CONV => RELU => CONV => RELU => POOL layer set.\n",
    "    my_model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    my_model.add(Activation(\"relu\"))\n",
    "    my_model.add(BatchNormalization(axis=channel_dimensions))\n",
    "    my_model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    my_model.add(Activation(\"relu\"))\n",
    "    my_model.add(BatchNormalization(axis=channel_dimensions))\n",
    "    my_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    my_model.add(Dropout(0.25))\n",
    "\n",
    "    # First (and only) set of FC => RELU layers\n",
    "    my_model.add(Flatten())\n",
    "    my_model.add(Dense(512))\n",
    "    my_model.add(Activation(\"relu\"))\n",
    "    my_model.add(BatchNormalization())\n",
    "    my_model.add(Dropout(0.5))\n",
    "\n",
    "    # Softmax classifier.\n",
    "    my_model.add(Dense(classes))\n",
    "    my_model.add(Activation(\"softmax\"))\n",
    "\n",
    "    # Return the constructed network architecture.\n",
    "    return my_model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Loss function —This measures how accurate the model is during training. \n",
    "We want to minimize this function to \"steer\" the model in the right direction.\n",
    "\n",
    "Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
    "\n",
    "Metrics —Used to monitor the training and testing steps. The following example uses accuracy, \n",
    "the fraction of the images that are correctly classified\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the optimizer and the model.\n",
    "opt = SGD(lr=LEARNING_RATE, momentum=0.9, decay=LEARNING_RATE / NUM_EPOCHS)\n",
    "model = build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "\"\"\"\n",
    "Feed the training data to the model—in this example, the train_images and train_labels arrays.\n",
    "\n",
    "The model learns to associate images and labels.\n",
    "\n",
    "We ask the model to make predictions about a test set—in this example, the test_images array. \n",
    "We verify that the predictions match the labels from the test_labels array.\n",
    "\"\"\"\n",
    "\n",
    "# Train the model.\n",
    "train_model = model.fit(train_images_reshaped, train_labels_one_hot,\n",
    "                        validation_data=(test_images_reshaped, test_labels_one_hot),\n",
    "                        batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Evaluate accuracy.\n",
    "\"\"\"\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images_reshaped, test_labels_one_hot)\n",
    "\n",
    "print()\n",
    "print('Test dataset accuracy:', test_acc)\n",
    "print('Test dataset loss:', test_loss)\n",
    "print()\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Make predictions.\n",
    "\"\"\"\n",
    "predictions = model.predict(test_images_reshaped)\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    \"\"\"\n",
    "    Function outputs a graph of the image.\n",
    "\n",
    "    :param i: counter variable.\n",
    "    :param predictions_array: array of all predictions made.\n",
    "    :param true_label: actual identity of apparel in image.\n",
    "    :param img: fashion apparel image.\n",
    "    :return: nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100 * np.max(predictions_array),\n",
    "                                         class_names[true_label]), color=color)\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    \"\"\"\n",
    "    Function outputs the prediction array with set of confidence values associated with each class.\n",
    "\n",
    "    :param i: counter variable.\n",
    "    :param predictions_array: array of all predictions made.\n",
    "    :param true_label: actualy identity of apparel in image.\n",
    "    :return: nothing.\n",
    "    \"\"\"\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    this_plot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    this_plot[predicted_label].set_color('red')\n",
    "    this_plot[true_label].set_color('blue')\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def visualize_training_results(predictions_array):\n",
    "    \"\"\"\n",
    "    Function visualizes the results of training the model as a summary of statistics and a plot\n",
    "    of training loss and accuracy on the dataset.\n",
    "\n",
    "    :return: Nothing.\n",
    "    \"\"\"\n",
    "    # Show a nicely formatted classification report.\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    print(classification_report(test_labels_one_hot.argmax(axis=1), predictions_array.argmax(axis=1),\n",
    "                                target_names=class_names))\n",
    "\n",
    "    # Plot the training loss and accuracy (for each epoch).\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_model.history[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"training_loss_accuracy_plot.png\")\n",
    "\n",
    "    # Plot the first X test images, their predicted label, and the true label.\n",
    "    # Color correct predictions in blue, incorrect predictions in red.\n",
    "    num_rows = 10\n",
    "    num_cols = 5\n",
    "    num_images = num_rows * num_cols\n",
    "    plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
    "        plot_image(i, predictions, test_labels, test_images)\n",
    "        plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n",
    "        plot_value_array(i, predictions, test_labels)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "def single_image_prediction_results():\n",
    "    \"\"\"\n",
    "    Predict probabilities for a single image.\n",
    "\n",
    "    :return: Nothing.\n",
    "    \"\"\"\n",
    "\n",
    "    import random\n",
    "    random_image = random.randint(1, 10000)\n",
    "\n",
    "    # Prediction sample.\n",
    "    print()\n",
    "    print(\"Prediction for the randomly chosen image:\")\n",
    "    print(predictions[random_image])\n",
    "    print()\n",
    "\n",
    "    # Get the highest confidence value from the prediction array.\n",
    "    print(\"Highest class confidence value for the image:\")\n",
    "    print(np.argmax(predictions[random_image]))\n",
    "\n",
    "    # Confirm against associated test label.\n",
    "    print(\"Associated test label value for the image:\")\n",
    "    print(test_labels[random_image])\n",
    "    print()\n",
    "\n",
    "    # Grab an image from the test dataset.\n",
    "    image = test_images_reshaped[random_image]\n",
    "    print(\"Randomly chosen image's shape: \")\n",
    "    print(image.shape)\n",
    "    print()\n",
    "    # Add the image to a batch where it's the only member.\n",
    "    image = (np.expand_dims(image, 0))\n",
    "    print(\"Randomly chosen image's shape in batch it was added to: \")\n",
    "    print(image.shape)\n",
    "    print()\n",
    "    # Predict the images in the batch.\n",
    "    predictions_single = model.predict(image)\n",
    "    print(\"Randomly chosen image's batch prediction results: \")\n",
    "    print(predictions_single)\n",
    "    print()\n",
    "\n",
    "    # Visualize the results of the batch image predictions.\n",
    "    plot_value_array(0, predictions_single, test_labels)\n",
    "    _ = plt.xticks(range(10), class_names, rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Get the max confidence value result signifying which class it belongs to in the labels.\n",
    "    print(\"Highest class confidence value for the image in the batch:\")\n",
    "    print(np.argmax(predictions_single[0]))\n",
    "\n",
    "    # Confirm against associated test label.\n",
    "    print(\"Associated test label value for the image in the batch:\")\n",
    "    print(test_labels[random_image])\n",
    "    print()\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\"\"\"\n",
    "Main function.  Execute the program.\n",
    "\"\"\"\n",
    "# Debug variable.\n",
    "debug = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print()\n",
    "\n",
    "    if debug:\n",
    "        # Visualize 0th image, predictions, and prediction array.\n",
    "        i = 0\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_image(i, predictions, test_labels, test_images)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_value_array(i, predictions, test_labels)\n",
    "        plt.show()\n",
    "\n",
    "        # Visualize the 12th image, predictions, and prediction array.\n",
    "        i = 12\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_image(i, predictions, test_labels, test_images)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_value_array(i, predictions, test_labels)\n",
    "        plt.show()\n",
    "\n",
    "    ##############################################\n",
    "\n",
    "    # Predict for a single image.\n",
    "    single_image_prediction_results()\n",
    "\n",
    "    ##############################################\n",
    "\n",
    "    # Visualize the training and prediction results.\n",
    "    visualize_training_results(predictions)\n",
    "\n",
    "############################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "#### Note 1:  The above results are from fast training with Conv2D() layers disabled.\n",
    "\n",
    "#### Note 2: Leaving the cell below as \"code comments\" as I haven't figured out how to easily format it to look exactly as it comes out in the output console in Pycharm using Markdown.  The results below are from training with 2 Conv2D() layers enabled directly from within PyCharm in the \"homework4_part3.py\" file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m39\u001b[0m\n\u001b[1;33m    T-shirt/top       0.87      0.90      0.89      1000\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Results from overnight training:\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "LEARNING_RATE = 1e-2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "Test dataset accuracy: 0.9336\n",
    "Test dataset loss: 0.1849521788418293\n",
    "\n",
    "\n",
    "\n",
    "Prediction for the randomly chosen image:\n",
    "[3.9291081e-10 3.1192984e-10 1.3035477e-10 5.3126011e-12 4.1941251e-12\n",
    " 9.9999607e-01 3.2498469e-11 2.7543354e-07 1.3105337e-09 3.7321797e-06]\n",
    "\n",
    "Highest class confidence value for the image:\n",
    "5\n",
    "Associated test label value for the image:\n",
    "5\n",
    "\n",
    "Randomly chosen image's shape: \n",
    "(28, 28, 1)\n",
    "\n",
    "Randomly chosen image's shape in batch it was added to: \n",
    "(1, 28, 28, 1)\n",
    "\n",
    "Randomly chosen image's batch prediction results: \n",
    "[[3.9291231e-10 3.1193104e-10 1.3035527e-10 5.3126219e-12 4.1941494e-12\n",
    "  9.9999607e-01 3.2498594e-11 2.7543430e-07 1.3105362e-09 3.7321938e-06]]\n",
    "\n",
    "Highest class confidence value for the image in the batch:\n",
    "5\n",
    "Associated test label value for the image in the batch:\n",
    "5\n",
    "\n",
    "[INFO] evaluating network...\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    " T-shirt/top       0.87      0.90      0.89      1000\n",
    "     Trouser       0.99      0.99      0.99      1000\n",
    "    Pullover       0.89      0.91      0.90      1000\n",
    "       Dress       0.93      0.94      0.93      1000\n",
    "        Coat       0.89      0.91      0.90      1000\n",
    "      Sandal       0.99      0.99      0.99      1000\n",
    "       Shirt       0.83      0.75      0.79      1000\n",
    "     Sneaker       0.97      0.98      0.98      1000\n",
    "         Bag       0.99      0.99      0.99      1000\n",
    "  Ankle boot       0.98      0.97      0.97      1000\n",
    "\n",
    "   micro avg       0.93      0.93      0.93     10000\n",
    "   macro avg       0.93      0.93      0.93     10000\n",
    "weighted avg       0.93      0.93      0.93     10000\n",
    "\n",
    "\n",
    "Process finished with exit code 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "I let the results in the cell above train overnight.  I hit \"run\" and then went to sleep and woke up in the morning with these results.  My older laptop with Nvidia Geforce 780M in SLI only has Nvidia CUDA Compute version 3.0, which does not satisfy the requirements to use GPU's with Tensorflow.  Tensorflow currently requires Nvidia CUDA Compute version 3.5 or above.  So, it takes a while using just the 6-core i7.  I would need to do this in my newer laptop with a Nvidia Geforce 1050 Ti if I want to use GPU support for Tensorflow and Keras.\n",
    "\n",
    "The fast training results with Conv2D() layers disabled only took a few minutes versus the few hours with both Conv2D() layers enabled.  Without the CNN layers, I managed a 88% accuracy with my current hyper parameters.  With the CNN layers, I managed a 93% accuracy with my current hyper parameters.  So, it seems the CNN does better with the Fashion MNIST then a non-CNN.\n",
    "\n",
    "Below, are the visualized results of training the model.  They have titles in each cell to indicate what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fashion MNIST Sample Training Image:\n",
    "\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_training_image[0].png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fashion MNIST Image Preprocessing:\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_training_images_preprocess.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image pre-processing grayscales the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Fashion MNIST Image Prediction Array (probabilities for each class for a single example)\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_image_prediction_array.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Fashion MNIST Loss and Accuracy Plot\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_image_loss_accuracy.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above plot of accuracy and loss, it seems validation loss began to exceed training loss around Epoch 12 or 13.  Training accuracy seemed to fit very tightly to validation accuracy after the 5th Epoch.  After the 12 or 13th Epoch, training accuracy exceeded validation accuracy by some minute margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### Fashion MNIST Image Prediction Results (array of examples)\n",
    "\n",
    "Note: Blue = correct prediction, Red = incorrect prediction<br>\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_test_images_prediction_results.png\" />\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_test_images_prediction_results2.png\" />\n",
    "\n",
    "<img style=\"float:center; transform: rotate(0deg); margin: 0 10px 10px 0\" src=\"fashion_mnist_test_images_prediction_results3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "A sequence of plots of an array of examples and their prediction results.  First a 5x5, then a 10x10, then a 20x20.  I think it stopped outputting to SciView in PyCharm once I tried to go even higher.  Otherwise, the 20x20 contains everything in the 10x10 and the 10x10 contains everything in the 5x5, and then some (upper left quadrant for the smaller set in the larger set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
